{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1d2fbd51",
   "metadata": {},
   "source": [
    "# MACHINE LEARNING - Group 09"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0944c1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# INTRO\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.metrics import adjusted_rand_score, fowlkes_mallows_score\n",
    "from sklearn.metrics import silhouette_score, homogeneity_score\n",
    "from sklearn.metrics import accuracy_score, precision_score, f1_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "\n",
    "df = pd.read_csv('popularity_score_dataset.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eea2c5ca",
   "metadata": {},
   "source": [
    "## Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b1a72c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DROPPING DUPLICATES AFTER MIXING ARTIST AND TRACK NAME\n",
    "\n",
    "df['artist_song'] = df['artists'] + ' - ' + df['track_name']\n",
    "df = df.drop_duplicates(subset='artist_song')\n",
    "\n",
    "artist_song_col = df.pop('artist_song')\n",
    "df.insert(0, 'artist_song', artist_song_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78bba7e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SEEING IF ENCODING ARTISTS MAKES SENSE\n",
    "\n",
    "num_unique = df['artists'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6126d80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DROPPING USELESS COLUMNS AND NULL VALUES\n",
    "\n",
    "df.drop('Unnamed: 0', axis=1, inplace=True)\n",
    "df.drop('album_name', axis=1, inplace=True)\n",
    "df.drop('artists', axis=1, inplace=True)\n",
    "df.drop('track_name', axis=1, inplace=True)\n",
    "df.drop('track_id', axis=1, inplace=True)\n",
    "\n",
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f9718fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ENCODING THE EXPLICIT FEATURE\n",
    "\n",
    "le = LabelEncoder()\n",
    "df['explicit'] = le.fit_transform(df['explicit'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b522d315",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DROPPING SONGS WITH POPULARITY = 0\n",
    "\n",
    "df = df.drop(df[df['popularity'] == 0].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aba1535",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# ONE HOT ENCODING GENRES\n",
    "\n",
    "encoder = OneHotEncoder()\n",
    "\n",
    "# Fit and transform the categorical variable\n",
    "one_hot_encoded = encoder.fit_transform(df[['track_genre']])\n",
    "\n",
    "# Convert the sparse matrix to a DataFrame\n",
    "one_hot_df = pd.DataFrame.sparse.from_spmatrix(one_hot_encoded)\n",
    "\n",
    "# Assign meaningful column names\n",
    "one_hot_df.columns = encoder.get_feature_names_out(['track_genre'])\n",
    "\n",
    "# Concatenate the one-hot encoded DataFrame with the original DataFrame\n",
    "df_encoded = pd.concat([df, one_hot_df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e45fca4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ONE HOT ENCODING KEY\n",
    "\n",
    "encoder = OneHotEncoder()\n",
    "\n",
    "# Fit and transform the categorical variable\n",
    "one_hot_encoded = encoder.fit_transform(df[['key']])\n",
    "\n",
    "# Convert the sparse matrix to a DataFrame\n",
    "one_hot_df = pd.DataFrame.sparse.from_spmatrix(one_hot_encoded)\n",
    "\n",
    "# Assign meaningful column names\n",
    "one_hot_df.columns = encoder.get_feature_names_out(['key'])\n",
    "\n",
    "# Concatenate the one-hot encoded DataFrame with the original DataFrame\n",
    "df_encoded = pd.concat([df_encoded, one_hot_df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b13c31b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove all the columns that contain null values\n",
    "df_encoded = df_encoded.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83c6a38a",
   "metadata": {},
   "source": [
    "## EDA (Extra)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f6d42b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CREATING A CLEANED CSV\n",
    "\n",
    "df.to_csv('popularity_cleaned.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "003d5118",
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXAMINING THE DISTRIBUTION OF THE DATA BY USING PLOTS\n",
    "\n",
    "features = ['popularity', 'duration_ms', 'danceability', 'energy', 'loudness', 'speechiness',\n",
    "            'acousticness', 'instrumentalness', 'liveness', 'valence', 'tempo',\n",
    "            'explicit', 'mode']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b5e30d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# HISTOGRAMS\n",
    "\n",
    "for feature in features:\n",
    "    plt.hist(df[feature], color='lightgreen', bins=30)\n",
    "    plt.title(feature)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb89531a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BOX PLOTS\n",
    "\n",
    "for feature in features:\n",
    "    plt.boxplot(df[feature], boxprops=dict(color='purple'),\n",
    "                whiskerprops=dict(color='green'),\n",
    "                medianprops=dict(color='green'))\n",
    "    plt.title(feature)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "811b59c5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# INVESTIGATING THE RELATIONSHIPS BETWEEN THE FEATURES USING A CORRELATION MATRIX\n",
    "\n",
    "corr = df.corr()\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(15,15))\n",
    "sns.heatmap(corr, annot=True, cmap=\"PiYG\", ax=ax)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61cf92eb",
   "metadata": {},
   "source": [
    "## Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b811f47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the genre column\n",
    "df_no_genre = df.drop('track_genre', axis=1)\n",
    "\n",
    "# Extract the numerical features to be used for clustering\n",
    "df_num = df_no_genre[features]\n",
    "\n",
    "# Scale the numerical features\n",
    "scaler = StandardScaler()\n",
    "df_num_scaled = scaler.fit_transform(df_num)\n",
    "\n",
    "# Create a new DataFrame with the scaled numerical features and the artist and track title columns\n",
    "df_scaled = pd.DataFrame(df_num_scaled, columns=features)\n",
    "df_scaled['artist_song'] = df_no_genre['artist_song']\n",
    "\n",
    "# Perform K-means clustering\n",
    "kmeans = KMeans(n_clusters=len(df['track_genre'].unique()), random_state=0).fit(df_scaled[features])\n",
    "\n",
    "# Add the cluster labels to the DataFrame\n",
    "df_scaled['cluster'] = kmeans.labels_\n",
    "\n",
    "# Print the cluster centroids\n",
    "centroids = pd.DataFrame(scaler.inverse_transform(kmeans.cluster_centers_), columns=features)\n",
    "print(centroids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b988d98",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_scaled[features]\n",
    "\n",
    "cluster_labels = kmeans.predict(df_scaled[features])\n",
    "true_labels = df['track_genre'].values\n",
    "\n",
    "# Silhouette score\n",
    "silhouette_avg = silhouette_score(df_scaled[features], cluster_labels)\n",
    "print(\"Silhouette Score:\", silhouette_avg)\n",
    "\n",
    "# Homogeneity score\n",
    "homogeneity = homogeneity_score(true_labels, cluster_labels)\n",
    "print(\"Homogeneity Score:\", homogeneity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a03b902b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the features\n",
    "clust = X.iloc[:, 1:]\n",
    "\n",
    "# Perform clustering\n",
    "kmeans = KMeans(n_clusters=113, random_state=42).fit(clust)\n",
    "\n",
    "# Reduce the number of dimensions to 2 using PCA\n",
    "pca = PCA(n_components=2)\n",
    "clust_pca = pca.fit_transform(clust)\n",
    "\n",
    "# Set the size of the figure\n",
    "plt.figure(figsize=(15, 15))\n",
    "\n",
    "# Plot the clusters\n",
    "plt.scatter(clust_pca[:, 0], clust_pca[:, 1], c=kmeans.labels_)\n",
    "\n",
    "# Set the labels for the plot\n",
    "plt.xlabel('PCA Component 1')\n",
    "plt.ylabel('PCA Component 2')\n",
    "plt.title('K-Means Clustering Results')\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "275c44a3",
   "metadata": {},
   "source": [
    "## Regression Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e380ee12",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# SPLITTING INTO TRAIN AND TEST \n",
    "X = df_encoded.drop(['popularity', 'artist_song', 'track_genre'], axis=1)\n",
    "y = df_encoded['popularity']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)\n",
    "\n",
    "# SCALING FEATURES\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f3e972c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LINEAR REGRESSION\n",
    "lr = LinearRegression()\n",
    "lr.fit(X_train, y_train)\n",
    "lr_pred = lr.predict(X_test)\n",
    "lr_r2 = r2_score(y_test, lr_pred)\n",
    "lr_rmse = mean_squared_error(y_test, lr_pred, squared=False)\n",
    "\n",
    "print('Linear Regression R2 score:', lr_r2)\n",
    "print('Linear Regression RMSE:', lr_rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b71662d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DECISION TREE\n",
    "dt = DecisionTreeRegressor(random_state=42)\n",
    "dt.fit(X_train, y_train)\n",
    "dt_pred = dt.predict(X_test)\n",
    "dt_r2 = r2_score(y_test, dt_pred)\n",
    "dt_rmse = mean_squared_error(y_test, dt_pred, squared=False)\n",
    "\n",
    "print('Decision Tree R2 score:', dt_r2)\n",
    "print('Decision Tree RMSE:', dt_rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75310c4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RANDOM FOREST\n",
    "rf = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "rf.fit(X_train, y_train)\n",
    "rf_pred = rf.predict(X_test)\n",
    "rf_r2 = r2_score(y_test, rf_pred)\n",
    "rf_rmse = mean_squared_error(y_test, rf_pred, squared=False)\n",
    "\n",
    "print('Random Forest R2 score:', rf_r2)\n",
    "print('Random Forest RMSE:', rf_rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcff271a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Support Vector Regression (SVR)\n",
    "svr = SVR()\n",
    "svr.fit(X_train_scaled, y_train)\n",
    "svr_pred = svr.predict(X_test_scaled)\n",
    "svr_r2 = r2_score(y_test, svr_pred)\n",
    "svr_rmse = mean_squared_error(y_test, svr_pred, squared=False)\n",
    "\n",
    "print('SVR R-squared:', svr_r2)\n",
    "print('SVR RMSE:', svr_rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e00d74b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gradient Boosting Regression\n",
    "gbr = GradientBoostingRegressor()\n",
    "gbr.fit(X_train_scaled, y_train)\n",
    "gbr_pred = gbr.predict(X_test_scaled)\n",
    "gbr_r2 = r2_score(y_test, gbr_pred)\n",
    "gbr_rmse = mean_squared_error(y_test, gbr_pred, squared=False)\n",
    "\n",
    "print('Gradient Boosting R-squared:', gbr_r2)\n",
    "print('Gradient Boosting RMSE:', gbr_rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61a883b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# XGBOOST\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "# Create an XGBoost classifier\n",
    "xgb_model = xgb.XGBRegressor()\n",
    "# fit\n",
    "xgb_model = xgb_model.fit(X_train_scaled,  y_train)\n",
    "\n",
    "XGB_pred = xgb_model.predict(X_test_scaled)\n",
    "\n",
    "# # calculate evaluation metrics\n",
    "XGB_mse = mean_squared_error(y_test, XGB_pred)\n",
    "XGB_rmse = np.sqrt(XGB_mse)\n",
    "XGB_r2 = r2_score(y_test, XGB_pred)\n",
    "\n",
    "print('R-squared:', XGB_r2)\n",
    "print('RMSE:', XGB_rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85c645dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# XGBOOST WITH GRID SEARCH\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "# Define the parameter grid for grid search\n",
    "param_grid = {\n",
    "    'max_depth': [3, 5, 7],\n",
    "    'learning_rate': [0.1, 0.01, 0.001],\n",
    "    'n_estimators': [100, 500, 1000],\n",
    "}\n",
    "\n",
    "# Perform grid search\n",
    "grid_search = GridSearchCV(estimator=xgb_model, param_grid=param_grid, scoring='neg_mean_squared_error', cv=5)\n",
    "grid_search.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Get the best parameters and the best score\n",
    "best_params = grid_search.best_params_\n",
    "best_score = grid_search.best_score_\n",
    "\n",
    "# Use the best parameters to build the final model\n",
    "final_model = xgb.XGBRegressor(**best_params)\n",
    "final_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "XGB_GRID_pred = final_model.predict(X_test_scaled)\n",
    "\n",
    "# # calculate evaluation metrics\n",
    "XGB_GRID_mse = mean_squared_error(y_test, XGB_GRID_pred)\n",
    "XGB_GRID_rmse = np.sqrt(XGB_GRID_mse)\n",
    "XGB_GRID_r2 = r2_score(y_test, XGB_GRID_pred)\n",
    "\n",
    "print('R-squared:', XGB_GRID_r2)\n",
    "print('RMSE:', XGB_GRID_rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10558d9f",
   "metadata": {},
   "source": [
    "## Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c9ca7eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the target variable as popularity class\n",
    "df_encoded['popularity_class'] = pd.qcut(df_encoded['popularity'], q=4, labels=False)\n",
    "\n",
    "# Split into train and test sets\n",
    "X = df_encoded.drop(['popularity', 'popularity_class', 'artist_song', 'track_genre'], axis=1)\n",
    "y = df_encoded['popularity_class']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)\n",
    "\n",
    "# Scale the features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Random Forest Classifier\n",
    "rf_classifier = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf_classifier.fit(X_train, y_train)\n",
    "rf_pred = rf_classifier.predict(X_test)\n",
    "\n",
    "# Calculate evaluation metrics\n",
    "accuracy = accuracy_score(y_test, rf_pred)\n",
    "precision = precision_score(y_test, rf_pred, average='weighted')\n",
    "f1 = f1_score(y_test, rf_pred, average='weighted')\n",
    "\n",
    "# Print the evaluation metrics\n",
    "print('Accuracy:', accuracy)\n",
    "print('Precision:', precision)\n",
    "print('F1-score:', f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7de58285",
   "metadata": {},
   "source": [
    "## Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6f93f53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the confusion matrix\n",
    "\n",
    "conf_matrix = confusion_matrix(y_test, rf_pred)\n",
    "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues',)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
